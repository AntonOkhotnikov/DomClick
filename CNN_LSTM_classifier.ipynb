{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Bidirectional, Flatten, Embedding, MaxPooling1D, Dropout, LeakyReLU, Conv1D, BatchNormalization as BatchNorm\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>lstm_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fraud</td>\n",
       "      <td>[29, 11, 18, 9, 27, 28, 31, 2, 22, 8, 20, 3, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>[115, 18, 125, 94, 103, 27, 28, 122, 88, 118, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>[293, 126, 18, 110, 302, 176, 768, 767, 454, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>[115, 125, 2346, 2323, 1752, 716, 122, 171, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>[279, 11, 18, 276, 302, 1601, 2693, 1163, 248,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status                                         lstm_embed\n",
       "0  fraud  [29, 11, 18, 9, 27, 28, 31, 2, 22, 8, 20, 3, 7...\n",
       "1   good  [115, 18, 125, 94, 103, 27, 28, 122, 88, 118, ...\n",
       "2   good  [293, 126, 18, 110, 302, 176, 768, 767, 454, 1...\n",
       "3   good  [115, 125, 2346, 2323, 1752, 716, 122, 171, 13...\n",
       "4   good  [279, 11, 18, 276, 302, 1601, 2693, 1163, 248,..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "filename = '/data/embedding_LSTM.json'\n",
    "\n",
    "df = pd.read_json(path + filename)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_voc_size(array):\n",
    "    try:\n",
    "        return max(array)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "voc_size = max(df['lstm_embed'].apply(lambda x: find_voc_size(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove long sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " remove sentences with length more than maxlen. Maxlen is chosen according to the hists from explore_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_long_sent(df):\n",
    "    global maxlen\n",
    "    \n",
    "    tmp = df.lstm_embed.apply(len)\n",
    "    short = df[tmp <= maxlen]\n",
    "    \n",
    "    return short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10223, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 300  # maximum number of words in a sentence\n",
    "df_trunc = remove_long_sent(df)\n",
    "df_trunc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the distribution of classes before and after truncating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8267, 2) (2601, 2)\n",
      "(7810, 2) (2413, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df[df.status == 'good'].shape, df[df.status == 'fraud'].shape)\n",
    "print(df_trunc[df_trunc.status == 'good'].shape, df_trunc[df_trunc.status == 'fraud'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences with zeros at the end\n",
    "X_train = pad_sequences(df_trunc.lstm_embed, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10223, 300), (10223,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_status(status):\n",
    "    if status == 'good':\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "Y_train = df_trunc.status.apply(lambda status: transform_status(status))\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Bidir LSTM + CNN - classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /lyceum/ao2u17/.conda/envs/keras_env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 10)           108620    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 10)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 291, 128)          12928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 291, 128)          512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 291, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 72, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 40)                23840     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 328       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 146,237\n",
      "Trainable params: 145,981\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 8689 samples, validate on 1534 samples\n",
      "Epoch 1/20\n",
      "8689/8689 [==============================] - 37s 4ms/step - loss: 0.4878 - binary_accuracy: 0.7856 - val_loss: 0.4253 - val_binary_accuracy: 0.8201\n",
      "Epoch 2/20\n",
      "8689/8689 [==============================] - 28s 3ms/step - loss: 0.3165 - binary_accuracy: 0.8739 - val_loss: 0.4298 - val_binary_accuracy: 0.8207\n",
      "Epoch 3/20\n",
      "8689/8689 [==============================] - 30s 3ms/step - loss: 0.2227 - binary_accuracy: 0.9122 - val_loss: 0.4100 - val_binary_accuracy: 0.8259\n",
      "Epoch 4/20\n",
      "8689/8689 [==============================] - 29s 3ms/step - loss: 0.1753 - binary_accuracy: 0.9369 - val_loss: 0.4249 - val_binary_accuracy: 0.8429\n",
      "Epoch 5/20\n",
      "8689/8689 [==============================] - 29s 3ms/step - loss: 0.1403 - binary_accuracy: 0.9492 - val_loss: 0.4655 - val_binary_accuracy: 0.8331\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b2ac1cb79e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)  # fix the random numbers generator state\n",
    "\n",
    "features_per_word = 10  # number of dimensions for a word embedding\n",
    "hidden_units = 20  # number of hidden units in the LSTM\n",
    "batch_size = 64\n",
    "nb_epochs = 20\n",
    "nb_classes = 1\n",
    "dropout = 0.1\n",
    "# sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=2, verbose=1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(voc_size + 1, features_per_word, input_length=maxlen))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Conv1D(filters=128, kernel_size=10))\n",
    "model.add(BatchNorm())\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=4))\n",
    "\n",
    "model.add(Bidirectional(LSTM(hidden_units, dropout=dropout)))\n",
    "\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping], \n",
    "                   validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
